>[!def] Immagine di v.a.
>Sia $X$ una v.a. su $(\Omega, F, P)$.
>L'_Immagine_ di $X$ è l'insieme:
>$$
>Im(X) := \{ X(w): w \in \Omega \}
>$$
>-> $Im(X) \subseteq \mathbb{R}$ ==l'insieme dei valori assunti da== $X$.

>[!def] Variabile Aleatoria Discreta
>Una v.a. $X$ su $(\Omega, F, P)$ si dice **discreta** se $Im(X)$ è al più numerabile.
>>[!example] Nell'esempio dei 3 dadi
>>$Im(X_{1}) = I m(X_{2}) = I m(X_{3}) = \{ 1\dots 6 \}$, mentre $I m(Z) = \{ 3\dots 18 \}$ dove $Z = X_{1} + X_{2} + X_{3}$ -> $X_{1}, X_{2}, X_{3}, Z$ tutte v.a aleatorie

Altri esempi:
- **Variabili Aleatorie Costanti**:
  Sia $c \in \mathbb{R}$
  $$
  X(w) = c \quad \forall w \in \Omega$$
  definisce una v.a. discreta con $I m(X) = \{ c \}$
- **Variabili Aleatorie Indicatrici**:
  Sia $A \in F$ un evento.
  $$
  
  X(w) = \perp_{A}(w) = \begin{cases}
1 & \text{se } w \in A \\
0 & \text{altrimenti}
\end{cases}
  $$
  definisce una v.a. discreta con $I m(X) = \{ 0,1 \}$ a meno che $A$ non sia $\emptyset$ oppure $\Omega$
- **Prove ripetute e indipendenti**:
  Siano $C_{1},\dots, C_{n}\in F$ eventi indipendenti ed equiprobabili.
  Poniamo
  $$
  \begin{align}
X_{i}(w) &:= \perp_{C_{i}}(w), \quad i \in \{ 1, \dots, n \} \\
S_{n} &:= \sum_{i = 1}^n X_{i}(w) \\
T_{n}(w) &:= inf\{ i \in \{ 1, \dots, n \} : X_{i}(w) = 1 \}
\end{align}
  $$
  -> $X_{1}, \dots, X_{n}, S_{n}, T_{n}$ sono v.a. discrete con $I m(X_{i}) = \{ 0, 1 \}$, $I m(S_{n}) = \{ 0, \dots, n \}$, $I m(T_{n}) = \{ 1, \dots, n \} \cup \{ \infty \}$
  Interpretazione: 
  - $X_{i}$ successo o meno dell'i-esima prova
  - $S_{n}$ numero di successi in $n$ prove
  - $T_{n}$ istante di primo successo in $n$ prove
## Densità Discreta di $X$
>[!def] Densistà Discreta di $X$
>Sia $X$ una v.a. discreta su $(\Omega, F, P)$.
>La funzione $p_{x} : \mathbb{R} \mapsto [0, 1]$ data da
>$$
>p_{x}(x) := P(X = x), \quad x \in \mathbb{R}
>$$
>si dice **densità discreta** di $X$
>>[!important] Obbiettivo
>>Calcolare la probabilità degli eventi generati da una v.a. $X$, cioè gli eventi della forma $\{ X \in B \}, \quad B \subseteq \mathbb{R}$

> Nota:
> $p_{x}$ è una densità discreta **su $\mathbb{R}$** nel senso che $p_{x}$ ha valori in $[0, 1]$ e
> $$
> \sum_{x \in \mathbb{R}}p_{x}(x) = \sum_{x \in \mathrm{Im}(X)}p_{x}(x) \quad \text{| } p_{x}(x) = 0 \text{ se } x \not\in \mathrm{Im}(X) = \sum_{x \in \mathrm{Im}(X)}P(X = x)
> $$
> Ora $\Omega = \bigcup_{x \in \mathrm{Im}(X)}\{ X = x \}$ unione al più numerabile di eventi disgiunti a due a due -> $\sum_{x \in \mathrm{Im}(X)}P(X = x) = P(\Omega) = 1$ -> $\sum_{x \in \mathbb{R}}p_{x}(x) = 1$

La densità discreta $p_{x}$ di una v.a. discreta $X$ permette di calcolare le probabilità di tutti gli eventi generati da $X$:
$$
\begin{align}
P(X \in B) &= \sum_{x \in B}p_{x}(x) \\
&= \sum_{x \in B \cap \mathrm{Im}(X)} p_{x}(x) \text{ per ogni } B \in \mathcal B(\mathbb{R})
\end{align}
$$
-> $p_{x}$ determina la legge di $X$:
$$
P_{X}(B) = \sum_{x \in B}p_{x}(x) = \sum_{x \in B \cap \mathrm{Im}(X)}p_{x}(x) \quad B \in \mathcal B(\mathbb{R})
$$
==La formula vale in realtà per $B \subseteq \mathbb{R}$ arbitrario==

### Esempi $(\Omega, F, P)$ spazio di probabilità

#### Variabili Aleatorie Costanti
Sia $c \in \mathbb{R}$
Poniamo
$$
X(w) := c \quad \forall w \in \Omega
$$
-> densità discreta di $X$ è data da
$$
p_{x}(x) = \begin{cases}
1 & \text{se } x = c \\
0 & \text{altrimenti}
\end{cases}
$$

-> Legge di X
$$
P_{x}(B) = \begin{cases}
1 & \text{se } c \in B \\
0 & \text{altrimenti}
\end{cases} \quad B \subseteq \mathbb{R}
$$

> Nota:
> In questo caso $P_{x}$ non dipende dalla misura di probabilità $P$.

#### Variabili Aleatorie Indicatrici
Sia $A \in F$
Poniamo
$$
X(w) := \perp_{A}(w) = \begin{cases}
1 & \text{se } w \in A \\
0 & \text{altrimenti}
\end{cases} \quad w \in \Omega
$$
-> Densità discreta di $X$ è data da:
$$
p_{X}(x) = \begin{cases}
P(A) & \text{se } x = 1 \\
P(A^c) & \text{se } x = 0  \\
0 & \text{altrimenti}
\end{cases}
$$
-> Legge di $X$
$$
P_{X}(B) = \begin{cases}
1 & \text{se } 0 \in B \text{ e } 1 \in B \\
P(A) & \text{se } 0 \not\in B \text{ ma } 1 \in B\\
P(A^c) & \text{ se } 0 \in B \text{ ma } 1 \not\in B\\
0 & \text{altrimenti}
\end{cases}
$$

#### Prove ripetute indipendenti
Siano $C_{1} \dots C_{n}$ eventi indipendenti in $(\Omega, F, P)$ con $P(C_{i}) = q \quad \forall i \in \{ 1 \dots n \}$ con $q \in [0,1]$.
Come prima, poniamo
$$
  \begin{align}
X_{i}(w) &:= \perp_{C_{i}}(w), \quad i \in \{ 1, \dots, n \} \\
S_{n} &:= \sum_{i = 1}^n X_{i}(w) \\
T_{n}(w) &:= inf\{ i \in \{ 1, \dots, n \} : X_{i}(w) = 1 \}
\end{align}
$$
##### Densità discreta di $X$
- $X_{1} \dots X_n$ hanno tutti la stessa densità discreta data da
  $$
  p_{X_{i}}(x) = \begin{cases}
q & \text{se } x = 1 \\
1 - q & \text{se } x = 0 \\
0 & \text{altrimenti}
\end{cases}
  $$
> Nota
> $X_{1} \dots X_{n}$ hanno la stessa legge (**identicamente distribuite**) ma sono diverse come v.a.

##### Densità discreta discreta di $S_{n}$, ovvero che si verifichino **esattamente $x$** tra i $n$ eventi $C_{i}$
$$
p_{S_{n}}(x) = P(S_{n} = x) = \begin{cases}
\binom{n}{x} \cdot q^x \cdot (1 - q)^{n - x} & \text{se } x \in \{ 0\dots n \} \\
0 &\text{altrimenti}
\end{cases}
$$
Per ottenere la densità di $S_{n} = \sum X_{i}$, devi considerare **tutti i modi** in cui puoi ottenere una somma pari a $x$, cioè:
- In quanti modi puoi avere $x$ successi (cioè $X_{i}=1$)
- E $n-x$ fallimenti (cioè $X_i=0$)    

Per questo serve:
$$
P(S_{n} = x) = \binom{n}{x} \cdot q^x \cdot (1- q)^{n - x}
$$

Questa **non è** la somma delle $p_{X_{i}}$​​, ma una distribuzione completamente nuova che emerge **dalla combinazione** (non somma!) degli $X_{i}$.

>[!example]- Esempio Utile
>Immagina:
>- Hai 3 monete con $P(\text{testa})=q$
>- Vuoi sapere la probabilità che escano esattamente 2 teste.
>
> Non puoi fare:
> $$
> P(\text{2 teste}) = P(\text{testa}) + P(\text{testa}) + P(\text{croce})
> $$
> Bisogna considerare **tutti i modi** in cui 2 teste possono uscire e moltiplicare le probabilità
> $$
> P(\text{2 teste}) = \binom{3}{2} \cdot q^2 \cdot (1 - q)^1
> $$


##### Densità discreta di $T_{n}$
$$
p_{T_{n}}(x) = P(T_{n} = x) = \begin{cases}
q \cdot (1-q)^{x-1} & \text{se } x \in \{ 1 \dots n \} \\
(1 - q)^n & \text{se } x = \infty \\
0 & \text{altrimenti}
\end{cases}
$$
Per avere 
$$
T_{n} = x
$$
cioè: **il primo successo avviene alla prova numero xxx**, devono succedere due cose:
1. Le **prime** $x-1$ prove devono essre **fallimentari**: $X_{1} = 0, \dots, X_{x - 1} = 0$
2. La $x$-**esima** prova deve essere un **successo**: $X_{x} = 1$

Poiché le $X_{i}$ sono indipendenti, la probabilità è:
$$
P(T_{n} = x) = P(X_{1} = 0) \cdots P(X_{x-1} = 0) \cdot P(X_{x} = 1) = (1-q)^{x-1} \cdot q
$$
Naturalmente questo vale **se e solo se** $x \in \{ 1 \dots n \}$.
#### Infinite prove ripetute e indipendenti
Siano $C_{1}, C_{2}, \dots$  eventi indipendenti ed equiprobabili con $P(C_{i}) = q$
Poniamo
$$
T(w) = inf\{ i \in \mathbb{N} : X_{i}(w) = 1 \}
$$
dove $X_{i}(w) = \perp_{C_{i}}(w)$
-> densità discreta di $T$ è data da
$$
P_{T}(x) = \begin{cases}
q \cdot (1 - q)^{x - 1} & \text{se } x \in \mathbb{N} \\
0 & \text{altrimenti}
\end{cases}
$$
purché ==$q > 0$==, se $q \in (0, 1]$, allora $\lim_{ n \to \infty }(1 - q)^n =0$

## Distribuzioni notevoli di v.a. discrete
Sia $X$ una v.a. discreta su $(\Omega, F, P)$ con densità discreta $p_X$.
### Distribuzione di Bernoulli
$X$ ha distribuzione di Bernoulli di parametro $q \in [0,1]$ se
$$
p_{X}(z) = \begin{cases}
q & \text{se } z = 1 \\
1 - q & \text{se } z = 0 \\
0 & altrimenti
\end{cases} \quad z\in\mathbb{R}
$$
Ovvero la probabilità di ottenere 1 è $q$, mentre di ottenere $1 - q$ è 0
In simboli:
$$
X \sim \text{Ber}(q)
$$

### Distribuzione di Rademacher
$X$ ha distribuzione di Rademacher di parametro $q \in [0,1]$ se
$$
p_{X}(z) = \begin{cases}
q & \text{se } z = 1 \\
1 - q & \text{se } z = -1 \\
0 & \text{altrimenti}
\end{cases} \quad z \in \mathbb{R}
$$
Ovvero la probabilità di ottenere 1 è $q$, mentre di ottenere $1 - q$ è -1
In simboli:
$$
X \sim \text{Rad}(q)
$$
>[!info]
>Rademacher è come Bernoulli, ma concentrata su $\{ -1, 1 \}$ anziché su $\{ 0, 1 \}$

### Distribuzione Binomiale
$X$ ha distribuzione binomiale di parametri $n \in \mathbb{N}, q \in [0,1]$ se
$$
p_{X}(z) = \begin{cases}
\binom{n}{z} \cdot q^z \cdot (1-q)^{n - x} & \text{se } z \in \{ 0, \dots, n \} \\
0 & \text{altrimenti}
\end{cases}
$$
Ovvero la probabilità di avere $z$ numeri di successi in $n$ prove ripetute e indipendenti
In simboli:
$$
X \sim \text{Bin}(n,q)
$$
> Nota $(n = 1)$
> $$\text{Bin}(1,q) = \text{Ber}(q)$$

### Distribuzioni Ipergeometriche
$X$ ha distribuzione ipergeometrica di parametri $N \in \mathbb{N}, M \in \{ 0, \dots, N \}, n \in \{ 1, \dots, N \}$ se
$$
p_{X}(z) = \begin{cases}
\frac{\binom{M}{z} \cdot \binom{N - M}{n - z}}{\binom{N}{n}} & \text{se } z \in \{ 0, \dots, n \land M \} \\
0 & \text{altrimenti}
\end{cases}
$$
Ovvero la probabilità, per esempio, di pescare $z$ palline rosse in $n$ estrazioni senza reinserimento da un'urna con $N$ palline di cui esattamente $M$ sono rosse.
🔴 $\binom{M}{z}$
-> Conta **quanti modi** puoi scegliere $z$ rosse **dalle** $M$ **rosse disponibili**.
❌ $\binom{N - M}{n - z}$
-> Conta **quanti modi** puoi scegliere $n - z$ palline **non rosse** dalle $N - M$ palline rimanenti.
➗ $\binom{N}{n}$
-> È il numero totale di modi di scegliere $n$ palline da $N$, indipendentemente dal colore.
In simboli
$$
X \sim \text{Iper}(N,M,n)
$$

### Distribuzione Uniforme Discreta
$X$ ha distribuzione uniforme discreta su un insieme $B \subset \mathbb{R}$ **finito** se
$$
p_{X}(z) = \begin{cases}
\frac{1}{|B|} & \text{se } z \in B \\
0 & \text{altrimenti}
\end{cases}
$$
Ovvero, per esempio, la possibilità che $z$ sia un numero segnato da un dato regolare equilibrato.
In simboli
$$
X \sim \text{Unif}(B)
$$

### Distribuzione di Poisson
$X$ ha distribuzione di Poisson di parametro $\lambda > 0$ se
$$
p_{X}(z)=\begin{cases}
e^{-\lambda} \cdot \frac{\lambda^z}{z!} & \text{se } z \in \mathbb{N}_{0} = \{ 0, 1, 2, \dots \} \\
0 & \text{altrimenti}
\end{cases}
$$
Ovvero, per esempio, la probabilità che $z$ sia il numero di "arrivi"(richieste / clienti/pacchetti dati) in un determinato intervallo di tempo; dove $\lambda$ dà l'intensità
In simboli
$$
X \sim \text{Poiss}(\lambda)
$$